\documentclass{article}

\usepackage{tabularx}
\usepackage{booktabs}
\usepackage{cite}

\title{Problem Statement and Goals\\\progname}

\author{\authname}

\date{}

\input{../Comments}
\input{../Common}

\begin{document}

\maketitle

\begin{table}[hp]
\caption{Revision History} \label{TblRevisionHistory}
\begin{tabularx}{\textwidth}{llX}
\toprule
\textbf{Date} & \textbf{Developer(s)} & \textbf{Change}\\
\midrule
2025-09-22 & Nirmal, Sathurshan, Omar, Kalp, Jay & Initial Write-up\\
2025-09-29 & Jay & Update goals and stretch goals\\
2025-11-04 & Kalp & Revision from TA feedback\\
2025-11-20 & Sathurshan & Update Extras\\
2025-12-12 & Omar & Address TA feedback for goals and stakeholders.\\
\bottomrule
\end{tabularx}
\end{table}

\setlength{\parindent}{0pt}

\newpage{}

\section{Problem Statement}

\subsection{Problem}

Individuals who are deaf or hard of hearing tend to have difficulties with
staying situationally aware, generally leading to increased risk of injury. Many
safety cues such as ``the sounds of a tea kettle, the warning beep as a fork lift
backs up, and the engine of an oncoming car may be missed''. \cite{Masterson2016}
General sound cues such as someone calling their name, or a phone ringing, may
also be missed, often leading to miscommunication and elevated frustration. With
1 in 10 Canadians being impacted by hearing loss \cite{Healthing2025}, there are
over 4 million individuals in Canada dealing with these struggles every day.

While existing assistive technologies such as hearing aids, smart glasses with
speech transcription, and home alert systems address some aspects of this
problem, they leave critical gaps. Hearing aids amplify sounds but do not assist
profoundly deaf individuals or provide visual directional cues. Transcription
glasses focus solely on speech and ignore environmental sounds. Home alert
systems are stationary and predetermined, lacking portability and real-time
directional awareness. None of these solutions provide real-time, wearable,
directional localization of environmental sounds, leaving individuals vulnerable
to missing important safety cues such as approaching vehicles, warning beeps, or
emergency alerts.


\subsection{Inputs and Outputs}

The high level input of the system is the audio from the surrounding
environments, with the output being a visual indication of the direction of
audio sources and their respective classifications (ex. 'car on your left',
'phone on your right', 'kettle on your front', etc. where 'car' would be 
the classification and 'on your left' would be the direction).

\subsection{Stakeholders}

The primary stakeholder identified for this project are individuals whom are
deaf or hard of hearing. The project will be designed with their needs in mind
and they will benefit the most from increased situational awareness. 
\\[\baselineskip]
Secondary stakeholders identified include individuals who have their ears 
covered for any reason. The brain exploits how the human 
ear shape changes waveforms hitting the eardrum from various directions to 
localize sound direction. Placing covers on ears such as noise cancelling 
headphones severely degrades 
the brain's ability to localize sound in addition to very little sound being 
transmitted through noise cancelling headphones. The same reasoning applies for 
construction workers who have to wear large ear muffs to protect their hearing 
\cite{HIL_HearingCues}. 
\\[\baselineskip]
Other tertiary stakeholders may include smart glasses and noise cancelling 
headphone manufacturers who may be interested in implementing the resulting 
technology from this project. 

\subsection{Environment}
The project is expected to perform adequately in indoor and outdoor environments.
The hardware utilized will be a compact micro-controller to allow future integration into
a wearable device form factor. The processor will be connected to a microphone
array over a suitable communication interface that is able to accommodate multiple
audio streams with adequate latency.

The software developed to be run on the hardware
will adhere to real-time constraints, most likely utilizing a real-time operating
system (RTOS) designed to execute on embedded micro-controller targets. 

The user facing hardware display is expected to be a pair of smart glasses with
an embedded display that the user can see. This display will be connected to the 
project hardware with a wired connection for prototyping purposes. 

\section{Goals}

\begin{itemize}
    \item Capture real-time audio from a microphone array with synchronized
    sampling.
    \item Accurate spatial analysis and real-time processing of audio sources
    surrounding the user.
    \item Estimate the angular direction of multiple audio sources relative
    to the user, providing reliable localization for practical use cases.
    \item Develop a minimal and easy to understand user interface that overlays
    on top of what the user sees without being intrusive.
    \item Meaningfully improve the situational awareness of primary and secondary
    stakeholders by means of the project with minimal effort required by end-users.
    \item Minimize the power usage of the software to extend the battery life of
    the host wearable. This will allow end-users to use the product for longer.
\end{itemize}
\section{Stretch Goals}

\begin{itemize}
    \item Classify sounds using audio fingerprinting with useful accuracy,
    allowing the system to recognize and differentiate between common sounds.
    \item Display audio classification, localized direction and transcription (
    when applicable) on smart glasses, supporting real-time and user-friendly interaction.
    \item Test the project with members of the hard of hearing community to 
    obtain valuable actionable feedback and improve the user experience.
\end{itemize}
\section{Extras}

% TODO: link to the actual documentation when we create them.
\begin{enumerate}
    \item Price + Hardware Selection Report
    \item Theory Report (DOA + Sound Classification with pyroom simulation
        integration)
\end{enumerate} 

\newpage{}

\section*{Appendix --- Reflection}

\begin{enumerate}
    \item What went well while writing this deliverable? 
    
    \textbf{Omar Alam:} I think all members of our team were proactive and
    genuinely interested in the project presented which made it easier to
    delegate and expect high quality work. 
    
    \textbf{Jay Sharma:} We aligned quickly on the problem and split
    responsibilities in a way that played to each person's strengths. Our
    LaTeX/Git workflow came together smoothly, which helped us iterate fast on
    the documents.

    \textbf{Kalp Shah:} I think we all had a good understanding of the project
    after discussing it in detail during the write up for the development plan.
    Due to this, everyone was able to quickly contribute to the problem
    statement and goals without much difficulty.

    \textbf{Sathurshan Arulmohan:} I focused on writing the Extras section of
    this deliverable. Since these items were pre-approved by the course
    instructor during the project approval stage, the writing process was
    straightforward and required minimal revisions.

    \textbf{Nirmal Chaudhari:} I think our team worked well when dividing up the
    tickets, and assigning reviewers for each PR. Moreover, we had frequent sync
    ups to discuss and reach out to our stakeholders, and determine the scope of
    our overall project. 

    \item What pain points did you experience during this deliverable, and how
    did you resolve them?

    \textbf{Omar Alam:} Since the project idea incorporates glasses with
    displays that are visible to the user, we had to do a significant amount of
    research to figure out if it was feasible in the time that we have. We
    resolved this by developing a contingency plan that would allow us to still
    allow us to develop the core algorithms without the display glasses.

    \textbf{Jay Sharma:} Our main pain point was deciding on the hardware that
     we would use for the project. We had to spend a significant amount of time
     researching the different options and their feasibility.
    
    \textbf{Kalp Shah:} I think we did end up spending a lot of time exploring
    the scope and feasibility of the project while writing the development plan
    which caused us to spend less time writing the problem statement and goals.
    We ended up writing it all on the day before the deadline which was not a
    problem (as mentioned above - we already knew what to write), but cause a
    bit of stress.

    \textbf{Sathurshan Arulmohan:} My main contribution to this deliverable was
    reviewing pull requests. The challenge was understanding the expected
    quality and depth since it is the team's first submission. To address this,
    we used Pull Requests to exchange feedback and propose improvements. This
    process helped the team establish documentation standards and align on
    expectations.

    \textbf{Nirmal Chaudhari:} Based on discussions with our supervisor, MVM, we
    were told it won't be easy to find a cheap solution that has 4 ADCs. To
    remain consistent with our project goals and requirements, having one ADC
    for each microphone was crucial for real time audio recognition. Our
    supervisor was very helpful in helping us overcome this challenge as he
    suggested a couple options from which Omar investigated further. We later
    met as a team and decided that we will only know if its compatible or not
    after actually buying hardware. 

    \item How did you and your team adjust the scope of your goals to ensure
    they are suitable for a Capstone project (not overly ambitious but also of
    appropriate complexity for a senior design project)?

    \textbf{Omar Alam:} My team and I spent a significant amount of time
    researching the feasibility of the project. Since the team does not have
    much experience with signal processing, we decided to consult with Dr.
    Mohrenschildt to get his opinion on the project. He provided us with
    valuable feedback on how to constraint our project goals to ensure that we
    can complete the project in the time we have.
    
    \textbf{Jay Sharma:} We started by mapping the problem space, did
    feasibility analyses, and set criteria around impact, difficulty, and time.
    We also checked in with Prof. Mohrenschildt to advise the direction of our
    project and keep the scope focused for the capstone timeline.

    \textbf{Kalp Shah:} A lot of what we did for defining the scope of the goals
    was done through research and consulting with Dr. Mohrenschildt and Dr.
    Smith. Dr. Mohrenschildt helped us better understand the expected time and
    resource costs of the project since he has experience with similar work and
    confirmed with us that our scope is neither too simple nor too ambitious for
    a Capstone project.

    \textbf{Sathurshan Arulmohan:} During the project proposal stage, the scope
    of the project was large. We had many features in mind, and we were not
    aware of the software and hardware complexities of achieving our vision. To
    refine this, each member shared their desired learning outcomes and
    technical interests. Through this discussion, we narrowed the scope of
    features and goals that balanced feasibility with sufficient challenge.

    \textbf{Nirmal Chaudhari:} Our team decided to go with the iterative
    approach for this project. During our first meeting with MVM, we discussed
    the feasibility of this project and our supervisor mentioned we should
    research each part individually first. This ensures that we can validate our
    project goals early on, and adjust as needed. 

\end{enumerate}  

\newpage{}

\bibliographystyle{IEEEtran}
\bibliography{../../refs/References}

\end{document}